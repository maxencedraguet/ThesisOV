\chapter{\color{oxfordblue} Conclusion and Outlook}\label{chap-Conclusion}
\ChapFrame
\vspace{-1cm}
This thesis aims to follow a logical order, starting from the theory underpinning the modern edifice of particle physics in Chapter~\ref{chap-theory}. The \gls{sm} has been extensively validated by many experiments across the world, in particular by the ATLAS Collaboration using data collected from proton-proton collisions in the \gls{lhc} as presented in Chapter~\ref{chapter-ATLAS}. Many properties of this particle discovered in 2012 have been confirmed to correspond to those of the predicted \gls{sm} Higgs boson. Nevertheless, the ATLAS Collaboration continues to systematically study the new particle anc challenge the \gls{sm} in evermore complex measurements, searching for any possible discrepancy between observations and theoretical predictions. This mission requires state-of-the-art detectors and reconstruction software. At its core, a particle physics analysis is statistical data analysis that is well suited to modern machine learning and artificial intelligence, as reviewed in Chapter~\ref{Chap-ML}. The recent progress in this field provides an exciting avenue of development for ATLAS, helping the Collaboration propel the performance of its software to new heights by designing effective network-based models for specific purposes. \\

One such promising area of development concerns jet flavour tagging, which has continuously benefitted from the adoption and development of advanced \gls{ml} in recent years, as outlined in Chapter~\ref{chap-ftag}. GN2, the newest generation of taggers of the ATLAS Collaboration, relies on a single multimodal network exploiting a Transformer Encoder at its core, with multiple tasks targeted to distil expert knowledge in the network. The state-of-the-art performance it delivers promises more refined measurements from the numerous analyses targetting heavy-flavour quarks in their final state during the ongoing Run 3 of the \gls{lhc}. \\

Two analyses benefitting starkly from flavour tagging are the \vhb\ and \vhc. These are now joined into the combined \vhbc\ analysis, described in Chapter~\ref{chap-VH}. At the time of writing, the analysis is in its last phase with final studies on the modelling and the fit framework, hence the results presented here are still blinded. Excitingly however, there are hints of great progress in the effort to observe the $H \rightarrow c\bar{c}$ decay and measure the $c$-quark Yukawa coupling. The expected upper limit on the signal strength has been reduced by a factor of 2.8 to 11.1 $\times$ \gls{sm} expectations, compared to the last published ATLAS result \cite{Collaboration:2721696}. Similarly, great progress is made in the precision measurement of the $H \rightarrow b\bar{b}$, with an expected signal strength sensitivity of 7.9 $\sigma$ corresponding to a 23\% improvement over the last ATLAS published result \cite{ATLAS:2021wqh}. For the first time, both production modes are expected to be observed at more than 5 $\sigma$ in the $H \rightarrow b\bar{b}$ decay mode, with respective significances of 5.5 $\sigma$ for $WH$ and 6.2 $\sigma$ for $ZH$. An \glsfirst{stxs} measurement of the different cross-sections of \vhb\ is also performed in stage 1.2.\\

To continue exploring the limit of our understanding in the particle physics realm, algorithmic and machine developments are required across the experiment. Collecting large datasets is crucial to analyses searching for rare signatures and performing precision measurements. The \vhbc\ analysis presented here suffers from large statistical uncertainties that will be improved with the addition of data. Collecting more data at higher energies require the detector to be operated i at more challenging conditions: more pile-up is the price of a higher instantaneous luminosity. The subdetectors must be upgraded to deal with this increased activity, with in particular finer-grain measurements expected to help performance. In this regard, the development of the next inner detector system called ITk is a promising avenue \cite{Bortoletto:2022wcx}. \\

Simultaneously to improving the hardware, the software of the ATLAS Collaboration must be upgraded to further push the sensitivity of the detector and deal with the future challenging conditions. In this respect, flavour tagging benefits greatly from adopting advanced new \gls{nn} architecture such as the Transformer, but also from the multimodal input and multitask paradigms to nimbly introduce expert knowledge. Future avenues of progress primarily relies on pursuing this path further, adding additional low-level input information and defining additional tasks to help the main classification objective. Performance is highly correlated with the number of parameters, and reliably training larger networks requires careful design, well-thought training procedures, large datasets, and optimised hyperparameters. Across science and industry, advanced machine learning plays a crucial role in the effort to modernise software capabilities. This is particularly the case in \gls{hep}, where the large databases measured from collisions or simulated are effectively exploited to create reliable and precise models. Such networks are trained for all the uses of the field: from generative \gls{ai} to effectively produced simulated samples, to fast network deployed on \glspl{fpga}- or \gls{gpu}-based triggers, \gls{dl} to reconstruct physics objects from the rich noisy set of low-level data, and finally \gls{ml} deploying in analyses to improve signal discrimination from the backgrounds and help constrain the modelling of the different processes. 